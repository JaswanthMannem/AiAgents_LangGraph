{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776a231a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9873e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from typing import Annotated, TypedDict\n",
    "import operator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage, AnyMessage\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a2bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(tavily_api_key=os.getenv(\"TAVILY_API_KEY\"),max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00f9fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_results=2 api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))\n"
     ]
    }
   ],
   "source": [
    "print(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc57775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage],operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ddd11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374f0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f250b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,model, tools, checkpointer, system = \"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\",self.call_openai)\n",
    "        graph.add_node(\"action\",self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exist_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\",\"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer = checkpointer)\n",
    "        self.model = model.bind_tools(tools)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {\"messages\":[message]}\n",
    "    \n",
    "    def exist_action(self, state: AgentState):\n",
    "        result = state[\"messages\"][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "    \n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling tool {t}\")\n",
    "            result = self.tools[t[\"name\"]].invoke(t[\"args\"])\n",
    "            results.append(ToolMessage(tool_call_id=t[\"id\"],name=t[\"name\"],content=str(result)))\n",
    "        print(\"Back to model\")\n",
    "        return {\"messages\":results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2f7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4da0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer_cm = SqliteSaver.from_conn_string(\":memory:\")\n",
    "checkpointer = contextlib.ExitStack().enter_context(checkpointer_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd47d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\",api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "abot = Agent(model, [tool], checkpointer=checkpointer, system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a282766",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "598af999",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5703ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NvLz1Jex1sebnWbvy013aYQU', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 151, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_92f14e8683', 'id': 'chatcmpl-BLDG1EUpm7KRqDWdoSImm4DnufX24', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7d918455-86ce-4535-9af0-cb2e5603ee34-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_NvLz1Jex1sebnWbvy013aYQU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 151, 'output_tokens': 23, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "Calling tool {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_NvLz1Jex1sebnWbvy013aYQU', 'type': 'tool_call'}\n",
      "Back to model\n",
      "[ToolMessage(content='[{\\'title\\': \\'Weather in San Francisco\\', \\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1744392695, \\'localtime\\': \\'2025-04-11 10:31\\'}, \\'current\\': {\\'last_updated_epoch\\': 1744392600, \\'last_updated\\': \\'2025-04-11 10:30\\', \\'temp_c\\': 14.4, \\'temp_f\\': 57.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 6.3, \\'wind_kph\\': 10.1, \\'wind_degree\\': 257, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1021.0, \\'pressure_in\\': 30.15, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 81, \\'cloud\\': 75, \\'feelslike_c\\': 13.9, \\'feelslike_f\\': 57.0, \\'windchill_c\\': 11.9, \\'windchill_f\\': 53.4, \\'heatindex_c\\': 12.4, \\'heatindex_f\\': 54.4, \\'dewpoint_c\\': 11.6, \\'dewpoint_f\\': 52.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 3.4, \\'gust_mph\\': 8.2, \\'gust_kph\\': 13.1}}\", \\'score\\': 0.9923824}, {\\'title\\': \\'Weather in San Francisco in April 2025 - Detailed Forecast\\', \\'url\\': \\'https://www.easeweather.com/north-america/united-states/california/city-and-county-of-san-francisco/san-francisco/april\\', \\'content\\': \\'Sunny\\\\n| 64° /55° | 0\\\\xa0in | 4 |  |\\\\n| Apr. 11 | \\\\nPartly cloudy\\\\n| 59° /53° | 0\\\\xa0in | 4 |  |\\\\n| Apr. 12 | \\\\nSunny\\\\n| 55° /50° | 0\\\\xa0in | 4 |  |\\\\n| Apr. 13 | \\\\nSunny\\\\n| 55° /48° | 0\\\\xa0in | 4 |  |\\\\n| Apr. 14 | \\\\nPatchy rain possible\\\\n| 51° /46° | 0.01\\\\xa0in | 3 |  |\\\\n| Apr. 15 | \\\\nSunny\\\\n| 59° /44° | 0\\\\xa0in | 4 |  |\\\\n| Apr. 16 | \\\\nOvercast\\\\n| 60° /44° | 0.1\\\\xa0in | 4 |  |\\\\n| Apr. 17 | \\\\nSunny\\\\n| 60° /46° | 0\\\\xa0in | 4 |  |\\\\n| Apr. 18 | \\\\nOvercast\\\\n| 62° /46° | 0.01\\\\xa0in | 4 |  |\\\\n| Apr. 19 | \\\\nCloudy\\\\n| 60° /48° | 0.02\\\\xa0in | 4 |  | [...] April\\\\nJanuaryFebruaryMarch\\\\nApril\\\\nMayJuneJulyAugustSeptemberOctoberNovemberDecember\\\\nWeather in San Francisco for April 2025\\\\nYour guide to San Francisco weather in April - trends and predictions\\\\nTemperatures\\\\n\\\\n\\\\nThe forecast for the next days in San Francisco predicts temperatures to be around 59\\\\xa0°F, close to the historical average. [...] San Francisco Weather April\\\\nMove between months or click on a day\\\\nMarch\\\\nMay\\\\n| Sun. | Mon. | Tue. | Wed. | Thu. | Fri. | Sat. |\\\\n| --- | --- | --- | --- | --- | --- | --- |\\\\n| \\\\n | \\\\n| 1  53° | 2  53° | 3  53° | 4  62° | 5  64° |\\\\n| 6  57° | 7  59° | 8  60° | 9  64° | 10  64° | 11  59° | 12  55° |\\\\n| 13  55° | 14  51° | 15  59° | 16  60° | 17  60° | 18  62° | 19  60° |\\\\n| 20  62° | 21  62° | 22  62° | 23  62° | 24  62° | 25  60° | 26  64° |\\\\n| 27  64° | 28  66° | 29  64° | 30  62° |  |  |  |\\', \\'score\\': 0.914176}]', name='tavily_search_results_json', tool_call_id='call_NvLz1Jex1sebnWbvy013aYQU')]\n",
      "[AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 14.4°C (57.9°F). The wind is blowing from the west-southwest at 6.3 mph (10.1 kph), and the humidity level is 81%. No precipitation is reported, and the visibility is 16 km.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 1347, 'total_tokens': 1417, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_92f14e8683', 'id': 'chatcmpl-BLDG4E3amUrZRwXozS93O8rMg2Bou', 'finish_reason': 'stop', 'logprobs': None}, id='run-9caa66cf-d5f9-4395-bf6e-045db6e252f7-0', usage_metadata={'input_tokens': 1347, 'output_tokens': 70, 'total_tokens': 1417, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b946b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "#     abot = Agent(model, [tool], checkpointer=checkpointer, system=prompt)\n",
    "\n",
    "#     messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "#     thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "#     for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "#         for v in event.values():\n",
    "#             print(v[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adedb3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"To determine which temperature is warmer, let's compare:\\n\\n- San Francisco's current temperature: 11.1°C (52.0°F).\\n\\nSince there is no other location mentioned for comparison, it's not possible to determine which one is warmer without another reference point. If you have another location or temperature in mind for comparison, please let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 795, 'total_tokens': 866, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'id': 'chatcmpl-BKoG9mdWfg1cM6lmEIfahPPnOh8YQ', 'finish_reason': 'stop', 'logprobs': None}, id='run-062703f6-5c45-45f6-86d4-90818063d4a2-0', usage_metadata={'input_tokens': 795, 'output_tokens': 71, 'total_tokens': 866, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5083c68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Could you please clarify what you are comparing to determine which is warmer? Are you asking about specific locations, time periods, clothing materials, or something else?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 149, 'total_tokens': 182, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'id': 'chatcmpl-BKoHvjrmA4xAPppIqXY2tSirlkHby', 'finish_reason': 'stop', 'logprobs': None}, id='run-cc164f65-692b-418c-9254-8acaca466530-0', usage_metadata={'input_tokens': 149, 'output_tokens': 33, 'total_tokens': 182, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "118cba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "\n",
    "stack = contextlib.AsyncExitStack()\n",
    "checkpointer = await stack.enter_async_context(AsyncSqliteSaver.from_conn_string(\":memory:\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af627eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(model, [tool], system=prompt, checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9f5f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_DIScswWAI1xWyEYVjCiUY59W', 'type': 'tool_call'}\n",
      "Back to model\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383aa16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
